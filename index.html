<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Vision AI</title>
    <meta name="description" content="A near-vision based, artificial intelligence powered Eye-Exam ">
    <meta name="author" content="Team SCRUMptious">
    <!-- Specifies keywords for search engines. It's not used much by search engines anymore. -->
    <meta name="keywords" content="Vision, eye exam, eye test, AI, eye, eyes, near sight, distance, app, website, results, accurate">
    <!-- security feature that instructs the browser to upgrade all HTTP requests to HTTPS -->
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
    <!-- The og: meta tags are used for Open Graph protocol, which allows any web page to become a rich object in a social graph. These are used by social media platforms like Facebook and LinkedIn when your website is shared. -->
    <meta property="og:title" content="VisionAI">
        <!-- This Open Graph protocol tag provides a brief description of the content, typically between 2 and 4 sentences. This will be used by social media platforms to describe the webpage when it's shared. -->
    <meta property="og:description" content="A near-vision based, artificial intelligence powered Eye-Exam.">
        <!-- This Open Graph protocol tag specifies the URL of the image that appears when the webpage is shared on social media platforms. Here, it's set to "thumbnail.jpg", which should be the path to the image file on your server. -->
    <meta property="og:image" content="favicon.png">
        <!-- This Open Graph protocol tag defines the canonical URL for your page. This URL is used by social media platforms to identify the unique URL of the webpage when it's shared. -->
    <meta property="og:url" content="https://vision-ai-host.web.app">        
        <!--The twitter:card meta tag is used by Twitter and specifies how your website should be displayed when shared on Twitter. The summary_large_image value means that a large image will be displayed in the Twitter card along with the title and description. -->
        <!-- The image, title, and description are taken from the corresponding Open Graph tags (og:image, og:title, and og:description). -->
    <meta name="twitter:card" content="summary_large_image">
        <!-- This gives instructions to web robots AKA crawlers, used by search engines to index the web. "index" tells the robot to index this page (i.e., include it in the search engine's results), "follow" tells it to follow links from this page to other pagesand index those as well. 
        <-- This is the default behavior for most web robots, so this tag is often included for completeness but isn't strictly necessary.. -->
    <meta name="robots" content="index, follow">
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.mjs"
    crossorigin="anonymous" type="module"></script>
    <script type="module">
      // Import the functions you need from the SDKs you need
      import { initializeApp } from "https://www.gstatic.com/firebasejs/10.7.1/firebase-app.js";
      import { getAnalytics } from "https://www.gstatic.com/firebasejs/10.7.1/firebase-analytics.js";
      // TODO: Add SDKs for Firebase products that you want to use
      // https://firebase.google.com/docs/web/setup#available-libraries
    
      // Your web app's Firebase configuration
      const firebaseConfig = {
        //apiKey: insert API key from firebase console, removed for  security purposes,
        authDomain: "vision-ai-host.firebaseapp.com",
        projectId: "vision-ai-host",
        storageBucket: "vision-ai-host.appspot.com",
        messagingSenderId: "771222648473",
        appId: "1:771222648473:web:ac4ea06c9460fffff16a08"
      };
    
      // Initialize Firebase
      const app = initializeApp(firebaseConfig);
      const analytics = getAnalytics(app);
    </script>
    
    <base href="/" />

    <meta name="color-scheme" content="light dark" minimum-scale=1.0, maximum-scale=1.0 />
    <meta name="theme-color" content="#light dark">

    <meta
      name="viewport"
      content="viewport-fit=cover, width=device-width, initial-scale=1.0"
    />
    <meta name="format-detection" content="telephone=no" />
    <meta name="msapplication-tap-highlight" content="no" />

    <link rel="manifest" href="/manifest.json" />
    <link rel="icon" href="/favicon.ico">
    <link rel="apple-touch-icon" href="/favicon.png" sizes="180x180">
    <link rel="mask-icon" href="/favicon.svg" color="#FFFFFF">
    <link rel="shortcut icon" type="image/png" href="/favicon.png" />
<!-- Include TensorFlow.js Core -->
<!-- Require the peer dependencies of face-landmarks-detection. -->
<!-- <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script> -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<!-- You must explicitly require a TF.js backend if you're not using the TF.js union bundle.
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>

Add the WebGPU backend to the global backend registry 
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu/dist/tf-backend-webgpu.js"></script>

 Adds the WebGL backend to the global backend registry -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

<!-- Adds the WASM backend to the global backend registry -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.js"></script>

<!-- Adds the CPU backend to the global backend registry -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-cpu"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>

<script>
  async function main() {
    // Your TensorFlow.js code here
  }

  // Example of choosing the backend based on device capabilities
  async function chooseBackend() {
    if (tf.backend.webgpu && navigator.gpu) {
      await tf.setBackend('webgpu');
    } else if (tf.backend.wasm) {
      await tf.setBackend('wasm');
    } else {
      await tf.setBackend('webgl');
    }
    await main();
  }

  chooseBackend();
</script>
<!-- 
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"
      crossorigin="anonymous"
    ></script> -->

    <!-- add to homescreen for ios -->
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="Vision AI" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />

  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
